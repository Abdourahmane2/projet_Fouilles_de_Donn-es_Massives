\documentclass[11pt,a4paper]{article}

% ============================================
% PACKAGES
% ============================================
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage[margin=2.5cm]{geometry}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{array}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{float}
\usepackage{caption}
\usepackage{fancyhdr}
\usepackage{setspace}
\usepackage{enumitem}

% ============================================
% CONFIGURATION
% ============================================
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    urlcolor=cyan
}

\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{Détection de Fraudes par Chèque}
\fancyhead[R]{M2 SISE}
\fancyfoot[C]{\thepage}

\setstretch{1.15}

% ============================================
% DEBUT DU DOCUMENT
% ============================================
\begin{document}

% ============================================
% PAGE DE TITRE
% ============================================
\begin{titlepage}
\centering
\vspace*{1cm}

{\Large\textbf{Université Lumière Lyon 2}}\\[0.3cm]
{\large Master 2 Informatique - SISE}\\[0.3cm]
{\large Fouille de Données Massives}\\[2cm]

{\Huge\textbf{Détection de Fraudes sur les Transactions par Chèque}}\\[1.5cm]

{\Large Projet : Sujet 1}\\[3cm]

{\large\textbf{Auteur(s) :} [Prénom NOM]}\\[0.5cm]
{\large\textbf{Encadrant :} Guillaume Metzler}\\[3cm]

{\large Année universitaire 2025-2026}\\[1cm]
{\large Rendu le : [Date]}

\end{titlepage}

% ============================================
% RÉSUMÉ
% ============================================
\section*{Résumé}
\addcontentsline{toc}{section}{Résumé}

Ce projet porte sur la détection de fraudes dans les transactions par chèque, un problème de classification binaire fortement déséquilibré. Les données proviennent du Fichier National des Chèques Irréguliers (FNCI) et d'une enseigne de grande distribution, comprenant 4,6 millions de transactions sur 10 mois.

Notre approche s'articule en deux parties : (1) maximiser le F1-Score en testant différentes méthodes de rééchantillonnage (SMOTE, ADASYN, sous-échantillonnage) couplées à des algorithmes de classification (Random Forest, XGBoost, LightGBM), et (2) maximiser la marge du commerçant en utilisant une matrice de coûts asymétrique.

Les résultats montrent que LightGBM combiné à ADASYN obtient le meilleur F1-Score (0.107 avec seuil optimisé), tandis que XGBoost avec optimisation du seuil maximise la marge avec un gain de +68 181 € par rapport à une stratégie sans détection, soit une amélioration de +3.5\%.

\vspace{0.5cm}
\textbf{Mots-clés :} Détection de fraude, Classification déséquilibrée, SMOTE, ADASYN, Random Forest, XGBoost, LightGBM

\newpage
\tableofcontents
\newpage

% ============================================
% 1. INTRODUCTION
% ============================================
\section{Introduction}

\subsection{Contexte}

Le chèque demeure un moyen de paiement répandu en France, notamment pour les transactions de montants élevés. Cependant, ce mode de paiement est sujet à des fraudes qui engendrent des pertes significatives pour les commerçants. Le Fichier National des Chèques Irréguliers (FNCI), géré par la Banque de France, recense les incidents de paiement et constitue une source précieuse pour développer des systèmes de détection automatique.

\subsection{Problématique}

La détection de fraude présente plusieurs défis majeurs :
\begin{itemize}[noitemsep]
    \item \textbf{Déséquilibre extrême} : les fraudes représentent moins de 1\% des transactions
    \item \textbf{Coûts asymétriques} : une fraude non détectée coûte bien plus qu'une fausse alerte
    \item \textbf{Évolution temporelle} : les patterns de fraude changent dans le temps
\end{itemize}

\subsection{Objectifs}

Ce projet vise deux objectifs distincts :
\begin{enumerate}[noitemsep]
    \item \textbf{Partie 1} : Maximiser le F1-Score, défini par $F = \frac{2TP}{2TP + FN + FP}$
    \item \textbf{Partie 2} : Maximiser la marge du commerçant selon une matrice de coûts
\end{enumerate}

\subsection{Organisation du rapport}

La Section 2 présente l'analyse des données. La Section 3 détaille la méthodologie employée. La Section 4 expose les résultats expérimentaux. Enfin, la Section 5 conclut ce travail.

% ============================================
% 2. ANALYSE DES DONNÉES
% ============================================
\section{Analyse des données}

\subsection{Présentation du jeu de données}

Les données proviennent d'une enseigne de grande distribution et d'organismes bancaires (FNCI, Banque de France). Chaque ligne représente une transaction par chèque effectuée entre février et novembre 2017.

\begin{table}[H]
\centering
\caption{Caractéristiques générales du jeu de données}
\begin{tabular}{ll}
\toprule
\textbf{Caractéristique} & \textbf{Valeur} \\
\midrule
Nombre de transactions & 4 646 773 \\
Nombre de variables & 23 \\
Période & Février 2017 - Novembre 2017 \\
Variable cible & FlagImpaye (0 = normal, 1 = fraude) \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Description des variables}

Les 23 variables se répartissent en plusieurs catégories :

\begin{itemize}[noitemsep]
    \item \textbf{Identifiants} : ZIBZIN (identifiant bancaire), IDAvisAutorisAtionCheque
    \item \textbf{Transaction} : Montant, DateTransaction, Heure
    \item \textbf{Comportement} : VérifianceCPT1-3 (nombre de transactions sur 1/3/7 jours), D2CB (ancienneté client), NbrMagasin3J
    \item \textbf{Scoring} : ScoringFP1-3 (scores d'anormalité par famille de produits)
    \item \textbf{Historique} : CA3TR, CA3TRetMtt (montants cumulés), DiffDateTr1-3 (écarts entre transactions)
    \item \textbf{Risque} : TauxImpNb\_RB (taux régional), TauxImpNB\_CPM (taux magasin)
\end{itemize}

\textbf{Remarque} : La variable CodeDecision n'est pas utilisable pour la prédiction car elle est acquise post-transaction.

\subsection{Split temporel}

Conformément au sujet, nous définissons :
\begin{itemize}[noitemsep]
    \item \textbf{Apprentissage} : 01/02/2017 au 31/08/2017 → 3 899 362 transactions
    \item \textbf{Test} : 01/09/2017 au 30/11/2017 → 747 411 transactions
\end{itemize}

\subsection{Déséquilibre des classes}

Le problème majeur est le fort déséquilibre des classes :

\begin{table}[H]
\centering
\caption{Distribution de la variable cible}
\begin{tabular}{lccc}
\toprule
\textbf{Ensemble} & \textbf{Normal (0)} & \textbf{Fraude (1)} & \textbf{Ratio} \\
\midrule
Apprentissage & 3 875 940 (99.40\%) & 23 422 (0.60\%) & 1:166 \\
Test & 740 838 (99.12\%) & 6 573 (0.88\%) & 1:114 \\
\bottomrule
\end{tabular}
\end{table}

On note que le taux de fraude est plus élevé dans l'ensemble de test (0.88\%) que dans l'apprentissage (0.60\%), suggérant une évolution temporelle des patterns de fraude.

\subsection{Analyse exploratoire}

L'analyse des corrélations révèle que les variables les plus discriminantes sont :
\begin{itemize}[noitemsep]
    \item ScoringFP1 : différence de +410\% entre fraudes et normales
    \item CA3TR : différence de +290\%
    \item ScoringFP2, ScoringFP3, VerifianceCPT3
\end{itemize}

Cependant, les corrélations avec la cible restent faibles (maximum $\approx$ 0.15), ce qui explique la difficulté intrinsèque de la tâche.

% ============================================
% 3. MÉTHODOLOGIE
% ============================================
\section{Méthodologie}

\subsection{Notations}

Soit $\mathcal{D} = \{(x_i, y_i)\}_{i=1}^n$ l'ensemble d'apprentissage où $x_i \in \mathbb{R}^d$ représente les features et $y_i \in \{0, 1\}$ la classe. On note $\hat{y}_i$ la prédiction du modèle et $p_i = P(y_i = 1 | x_i)$ la probabilité de fraude estimée.

\subsection{Métriques d'évaluation}

\subsubsection{F1-Score (Partie 1)}

Le F1-Score est la moyenne harmonique de la précision et du rappel :
\begin{equation}
    F_1 = \frac{2 \times Precision \times Recall}{Precision + Recall} = \frac{2TP}{2TP + FP + FN}
\end{equation}

\subsubsection{Marge (Partie 2)}

La marge totale est calculée selon la matrice de coûts :
\begin{itemize}[noitemsep]
    \item TN (accepter client normal) : $+0.05 \times m$
    \item FP (refuser client normal) : $-0.035 \times m$ (70\% de la marge perdue)
    \item TP (refuser fraudeur) : 0
    \item FN (accepter fraudeur) : perte variable selon $m$
\end{itemize}

La perte FN dépend du montant : 0\% si $m \leq 20$, 20\% si $m \leq 50$, 30\% si $m \leq 100$, 50\% si $m \leq 200$, 80\% sinon.

\subsection{Gestion du déséquilibre}

\subsubsection{SMOTE (Synthetic Minority Over-sampling Technique)}

SMOTE génère des exemples synthétiques de la classe minoritaire en interpolant entre exemples proches :
\begin{equation}
    x_{new} = x_i + \lambda \times (x_{nn} - x_i), \quad \lambda \in [0, 1]
\end{equation}

\subsubsection{ADASYN (Adaptive Synthetic Sampling)}

ADASYN étend SMOTE en générant plus d'exemples dans les zones difficiles (proches de la frontière de décision). Le nombre d'exemples pour $x_i$ est proportionnel à la densité d'exemples de classe opposée dans son voisinage.

\subsubsection{Sous-échantillonnage}

Réduit aléatoirement la classe majoritaire pour équilibrer les classes.

\subsubsection{Pondération des classes}

Attribue un poids plus élevé aux exemples de la classe minoritaire dans la fonction de coût.

\subsection{Algorithmes de classification}

\subsubsection{Random Forest}

Ensemble de $T$ arbres de décision entraînés sur des sous-échantillons bootstrap. La prédiction est obtenue par vote majoritaire.

\subsubsection{XGBoost / LightGBM}

Algorithmes de gradient boosting qui construisent séquentiellement des arbres pour corriger les erreurs des précédents. LightGBM utilise une croissance par feuille (leaf-wise) plus efficace.

\subsection{Optimisation du seuil}

Par défaut, on prédit fraude si $p_i \geq 0.5$. Pour les données déséquilibrées, nous recherchons le seuil $s^*$ optimal :
\begin{equation}
    s^* = \arg\max_{s \in [0,1]} \text{Métrique}(y, \mathbb{1}[p \geq s])
\end{equation}
où la métrique est le F1-Score (Partie 1) ou la marge (Partie 2).

% ============================================
% 4. EXPÉRIENCES
% ============================================
\section{Expériences}

\subsection{Protocole expérimental}

\textbf{Prétraitement} : Suppression des variables non pertinentes (Identifiant, CodeDecision, DateTransaction), correction des types de données. 18 features sont retenues.

\textbf{Méthodes testées} (minimum 5 requises) :
\begin{enumerate}[noitemsep]
    \item Random Forest (baseline, sans rééchantillonnage)
    \item Random Forest + SMOTE
    \item XGBoost avec pondération des classes
    \item LightGBM + ADASYN
    \item Random Forest + Sous-échantillonnage
\end{enumerate}

\textbf{Hyperparamètres} : n\_estimators=100, max\_depth=10-15, sampling\_strategy=0.5 pour SMOTE/ADASYN.

\subsection{Résultats - Partie 1 : F1-Score}

\begin{table}[H]
\centering
\caption{Comparaison des méthodes - F1-Score (seuil = 0.5)}
\begin{tabular}{lcccc}
\toprule
\textbf{Méthode} & \textbf{F1-Score} & \textbf{Precision} & \textbf{Recall} & \textbf{ROC-AUC} \\
\midrule
LightGBM + ADASYN & \textbf{0.0685} & 0.0388 & 0.2947 & 0.7219 \\
RF + SMOTE & 0.0483 & 0.0257 & 0.4059 & 0.7182 \\
RF + UnderSampling & 0.0465 & 0.0243 & 0.5425 & 0.7459 \\
RF Baseline & 0.0359 & 0.6836 & 0.0184 & 0.7426 \\
XGBoost Weighted & 0.0346 & 0.0178 & 0.6983 & 0.7517 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Analyse} : LightGBM + ADASYN obtient le meilleur F1-Score. Le RF Baseline a une précision élevée mais un rappel catastrophique (1.84\%). XGBoost Weighted a un rappel élevé mais trop de fausses alertes.

\subsubsection{Optimisation du seuil}

Pour LightGBM + ADASYN, le seuil optimal est 0.74 :

\begin{table}[H]
\centering
\caption{Impact de l'optimisation du seuil - LightGBM + ADASYN}
\begin{tabular}{lcc}
\toprule
\textbf{Configuration} & \textbf{Seuil} & \textbf{F1-Score} \\
\midrule
Par défaut & 0.50 & 0.0685 \\
Optimisé & 0.74 & \textbf{0.1070} \\
\midrule
\textbf{Amélioration} & & \textbf{+56\%} \\
\bottomrule
\end{tabular}
\end{table}

Avec le seuil optimisé, 583 fraudes sont détectées sur 6 573 (8.9\%), avec 3 744 fausses alertes.

\subsection{Résultats - Partie 2 : Marge}

\textbf{Référence} : Sans système de détection (tout accepter), la marge est de \textbf{1 941 852 €}.

\begin{table}[H]
\centering
\caption{Comparaison des marges par méthode}
\begin{tabular}{lrrrr}
\toprule
\textbf{Méthode} & \textbf{Marge (€)} & \textbf{Perte FP} & \textbf{Perte FN} & \textbf{TP} \\
\midrule
XGBoost optimisé & \textbf{2 010 033} & -17 345 & -242 304 & 628 \\
Ensemble & 1 998 133 & -11 806 & -267 656 & 440 \\
LightGBM (seuil opt) & 1 988 509 & -14 971 & -269 591 & 488 \\
RF + SMOTE opt & 1 978 646 & -3 337 & -307 710 & 179 \\
\textbf{Référence} & \textbf{1 941 852} & 0 & -352 608 & 0 \\
LightGBM (seuil 0.5) & 1 641 927 & -210 293 & -141 821 & 1 937 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Analyse} : XGBoost optimisé génère la meilleure marge avec +68 181 € par rapport à la référence (+3.5\%). Le modèle LightGBM avec seuil par défaut (0.5) fait \textit{perdre} de l'argent par rapport à la référence car il génère trop de fausses alertes.

\subsection{Discussion}

\textbf{Compromis Precision/Recall} : Un seuil bas détecte plus de fraudes mais génère plus de fausses alertes. Le seuil optimal dépend de l'objectif (F1 vs marge).

\textbf{Différence entre les deux parties} : Le meilleur modèle pour le F1-Score (LightGBM + ADASYN) n'est pas le meilleur pour la marge (XGBoost optimisé), car la marge prend en compte les montants des transactions.

\textbf{Importance du seuil} : L'optimisation du seuil est cruciale. Avec un mauvais seuil, le système de détection peut faire perdre de l'argent plutôt qu'en faire gagner.

% ============================================
% 5. CONCLUSION
% ============================================
\section{Conclusion}

\subsection{Synthèse}

Ce projet a permis de développer un système de détection de fraudes sur les transactions par chèque. Face au déséquilibre extrême des classes (1:166), les techniques de rééchantillonnage (SMOTE, ADASYN) et l'optimisation du seuil de décision se sont révélées essentielles.

\textbf{Partie 1} : Le meilleur modèle est LightGBM + ADASYN avec un F1-Score de 0.107 (seuil optimisé à 0.74), soit une amélioration de +56\% par rapport au seuil par défaut.

\textbf{Partie 2} : XGBoost avec optimisation du seuil maximise la marge avec un gain de +68 181 € (+3.5\%) par rapport à une stratégie sans détection.

\subsection{Limites}

\begin{itemize}[noitemsep]
    \item Taux de détection modeste : environ 9\% des fraudes détectées
    \item Corrélations faibles entre features et cible
    \item Drift temporel : le taux de fraude augmente entre train et test
\end{itemize}

\subsection{Perspectives}

\begin{itemize}[noitemsep]
    \item Feature engineering : créer des variables temporelles et comportementales
    \item Modèles plus complexes : réseaux de neurones, autoencodeurs
    \item Monitoring : surveillance du drift et réentraînement périodique
\end{itemize}

Le gain de 68 181 € justifie économiquement la mise en place d'un système de détection de fraude, même avec des performances de détection modestes.

\end{document}
