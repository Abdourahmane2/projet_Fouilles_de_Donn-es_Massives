% ============================================
% CHAPITRE 7 : ANNEXES
% ============================================

\section{Environnement technique}

\subsection{Langages et outils}

\begin{itemize}
    \item \textbf{Python} 3.9+
    \item \textbf{Jupyter Notebook} pour l'analyse exploratoire
    \item \textbf{Visual Studio Code} comme IDE
\end{itemize}

\subsection{Bibliothèques Python}

\begin{table}[H]
\centering
\caption{Bibliothèques utilisées}
\begin{tabular}{ll}
\toprule
\textbf{Bibliothèque} & \textbf{Usage} \\
\midrule
pandas & Manipulation des données \\
numpy & Calculs numériques \\
scikit-learn & Modèles ML et métriques \\
imbalanced-learn & Techniques de rééchantillonnage \\
xgboost & Modèle XGBoost \\
lightgbm & Modèle LightGBM \\
matplotlib & Visualisation \\
seaborn & Visualisation statistique \\
\bottomrule
\end{tabular}
\end{table}

\section{Structure du projet}

\begin{verbatim}
fraud-detection-project/
|-- config/
|   `-- config.py
|-- data/
|   |-- raw/
|   `-- processed/
|-- notebooks/
|   |-- 01_exploration.ipynb
|   |-- 02_preprocessing.ipynb
|   |-- 03_modeling.ipynb
|   `-- 04_margin_optimization.ipynb
|-- rapport_final/
|   |-- main.tex
|   |-- sections/
|   `-- figures/
|-- reports/
|   `-- figures/
|-- src/
|   |-- data_loader.py
|   |-- preprocessing.py
|   `-- evaluation.py
|-- models/
|-- requirements.txt
`-- README.md
\end{verbatim}


\section{Métriques d'évaluation}

\subsection{Définitions}

\begin{itemize}
    \item \textbf{TP (True Positive)} : Fraude correctement détectée
    \item \textbf{TN (True Negative)} : Transaction normale correctement classée
    \item \textbf{FP (False Positive)} : Fausse alerte (transaction normale classée fraude)
    \item \textbf{FN (False Negative)} : Fraude manquée (fraude classée normale)
\end{itemize}

\subsection{Formules}

\begin{align}
    Precision &= \frac{TP}{TP + FP} \\[0.3cm]
    Recall &= \frac{TP}{TP + FN} \\[0.3cm]
    F1\text{-}Score &= 2 \times \frac{Precision \times Recall}{Precision + Recall} \\[0.3cm]
    Accuracy &= \frac{TP + TN}{TP + TN + FP + FN} \\[0.3cm]
    Specificity &= \frac{TN}{TN + FP}
\end{align}

\section{Algorithmes de rééchantillonnage}

\subsection{SMOTE}

\textbf{Synthetic Minority Over-sampling Technique}

Pour chaque exemple $x_i$ de la classe minoritaire :
\begin{enumerate}
    \item Trouver les $k$ plus proches voisins de $x_i$ dans la classe minoritaire
    \item Sélectionner aléatoirement un voisin $x_{nn}$
    \item Créer un exemple synthétique : $x_{new} = x_i + \lambda \times (x_{nn} - x_i)$ où $\lambda \in [0,1]$
\end{enumerate}

\subsection{ADASYN}

\textbf{Adaptive Synthetic Sampling}

Extension de SMOTE qui génère plus d'exemples synthétiques pour les exemples difficiles à classifier (proches de la frontière de décision).

Le nombre d'exemples synthétiques pour chaque $x_i$ est proportionnel à :
\begin{equation}
    r_i = \frac{\Delta_i / k}{\sum_{j} \Delta_j / k}
\end{equation}

où $\Delta_i$ est le nombre de voisins de classe différente parmi les $k$ plus proches voisins.

\section{Code des fonctions principales}

\subsection{Calcul de la marge}

\begin{lstlisting}[language=Python, caption=Fonction de calcul de la marge]
def compute_fn_loss(montant):
    """Perte pour un Faux Negatif selon le montant."""
    if montant <= 20:
        return 0
    elif montant <= 50:
        return 0.2 * montant
    elif montant <= 100:
        return 0.3 * montant
    elif montant <= 200:
        return 0.5 * montant
    else:
        return 0.8 * montant

def compute_transaction_margin(y_true, y_pred, montant):
    """Marge pour une transaction."""
    marge_base = 0.05 * montant
    
    if y_true == 0 and y_pred == 0:  # TN
        return marge_base
    elif y_true == 0 and y_pred == 1:  # FP
        return -0.70 * marge_base
    elif y_true == 1 and y_pred == 0:  # FN
        return -compute_fn_loss(montant)
    else:  # TP
        return 0
\end{lstlisting}

\subsection{Optimisation du seuil}

\begin{lstlisting}[language=Python, caption=Recherche du seuil optimal]
def find_best_threshold_for_margin(y_true, y_proba, montants):
    """Trouve le seuil maximisant la marge."""
    thresholds = np.arange(0.01, 0.99, 0.01)
    margins = []
    
    for thresh in thresholds:
        y_pred = (y_proba >= thresh).astype(int)
        margin = compute_total_margin(y_true, y_pred, montants)
        margins.append(margin['total_margin'])
    
    best_idx = np.argmax(margins)
    return thresholds[best_idx], margins[best_idx]
\end{lstlisting}

\section{Tableaux de résultats détaillés}

\subsection{Partie 1 : Tous les modèles}

\begin{table}[H]
\centering
\caption{Résultats complets Partie 1}
\begin{tabular}{lccccc}
\toprule
\textbf{Modèle} & \textbf{F1} & \textbf{Prec.} & \textbf{Recall} & \textbf{AUC} & \textbf{Acc.} \\
\midrule
LightGBM + ADASYN & 0.0685 & 0.0388 & 0.2947 & 0.7219 & 92.95\% \\
RF + SMOTE & 0.0483 & 0.0257 & 0.4059 & 0.7182 & 85.94\% \\
RF + UnderSampling & 0.0465 & 0.0243 & 0.5425 & 0.7459 & 80.45\% \\
RF Baseline & 0.0359 & 0.6836 & 0.0184 & 0.7426 & 99.13\% \\
XGBoost Weighted & 0.0346 & 0.0178 & 0.6983 & 0.7517 & 65.75\% \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Partie 2 : Tous les modèles}

\begin{table}[H]
\centering
\caption{Résultats complets Partie 2}
\begin{tabular}{lcccc}
\toprule
\textbf{Modèle} & \textbf{Marge (€)} & \textbf{TP} & \textbf{FN} & \textbf{vs Réf.} \\
\midrule
XGBoost optimisé & 2 010 033 & 628 & 5 945 & +68 181 € \\
Ensemble & 1 998 133 & 440 & 6 133 & +56 282 € \\
LightGBM (seuil opt) & 1 988 509 & 488 & 6 085 & +46 658 € \\
RF + SMOTE opt & 1 978 646 & 179 & 6 394 & +36 795 € \\
Référence & 1 941 852 & 0 & 6 573 & - \\
Seuil adaptatif & 1 665 461 & 1 349 & 5 224 & -276 391 € \\
LightGBM (seuil 0.5) & 1 641 927 & 1 937 & 4 636 & -299 925 € \\
\bottomrule
\end{tabular}
\end{table}
